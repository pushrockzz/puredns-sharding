name: puredns-quick-test

on:
  workflow_dispatch:
    inputs:
      chunk_start:
        description: 'First chunk index this run will process (integer)'
        required: true
        default: '0'
      total_chunks:
        description: 'DEPRECATED: Total chunks is now auto-detected.'
        required: false
      run_counter:
        description: 'Automatic run counter for recursion (auto-incremented)'
        required: false
        default: '0'
      max_runs:
        description: 'Safety cap: stop after this many runs. If unset, it is auto-calculated.'
        required: false
        default: '999'
      words_per_chunk:
        description: 'Words per chunk file (lines_per_chunk).'
        required: false
        default: '50000'
      domains_count:
        description: 'How many test domains to generate (default = 5)'
        required: false
        default: '5'

env:
  WORKFLOW_FILE: puredns-quicktest.yml
  MATRIX_SIZE: '20'

jobs:
  prepare:
    name: prepare-wordlists-and-resolvers
    runs-on: ubuntu-latest
    env:
      COMBINED_WORDLIST: combined-wordlist.txt
    outputs:
      artifact-name: wordlists-artifact
      total-chunks: ${{ steps.finalize_prep.outputs.total-chunks }}
      effective-max-runs: ${{ steps.finalize_prep.outputs.effective-max-runs }}
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          persist-credentials: false
      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.23'
      - name: Install Go tools
        run: go install -v github.com/tomnomnom/anew@latest
      - name: Cache Raw Wordlists
        uses: actions/cache@v3
        with:
          path: |
            best-wordlist-level1.txt
            best-wordlist-level2.txt
          key: raw-wordlists-cache-v1-${{ runner.os }}
      - name: Fetch wordlists and Resolvers
        run: |
          if [ ! -f best-wordlist-level1.txt ]; then wget -qO best-wordlist-level1.txt https://raw.githubusercontent.com/trickest/wordlists/main/inventory/levels/level1.txt; fi
          if [ ! -f best-wordlist-level2.txt ]; then wget -qO best-wordlist-level2.txt https://raw.githubusercontent.com/trickest/wordlists/main/inventory/levels/level2.txt; fi
          wget -qO resolvers.txt https://raw.githubusercontent.com/rix4uni/resolvers/main/resolvers.txt
          wget -qO resolvers-trusted.txt https://raw.githubusercontent.com/and0x00/resolvers.txt/main/resolvers.txt
      - name: Build filter_wordlist tool
        run: |
          if [ -f "filter_wordlist.go" ]; then go build -o filter_wordlist filter_wordlist.go; fi

      - name: Cache Filtered Wordlist
        id: cache-filtered-wordlist
        uses: actions/cache@v3
        with:
          path: ${{ env.COMBINED_WORDLIST }}
          key: filtered-wordlist-cache-v1-${{ runner.os }}-${{ hashFiles('best-wordlist-*.txt', 'filter_wordlist.go') }}
      - name: Filter and Combine Wordlists
        if: steps.cache-filtered-wordlist.outputs.cache-hit != 'true'
        run: |
          if [ -f ./filter_wordlist ]; then
            ./filter_wordlist best-wordlist-level1.txt > best-wordlist-filtered.txt
            ./filter_wordlist best-wordlist-level2.txt > best-wordlist-level2-filtered.txt
          else
            cp best-wordlist-level1.txt best-wordlist-filtered.txt
            cp best-wordlist-level2.txt best-wordlist-level2-filtered.txt
          fi
          cat best-wordlist-filtered.txt best-wordlist-level2-filtered.txt | PATH=$HOME/go/bin:$PATH anew -q ${{ env.COMBINED_WORDLIST }}
      - name: Finalize Preparation and Split Chunks
        id: finalize_prep
        run: |
          mkdir -p domains wordlists results
          if [ ! -f "domains/domains.txt" ]; then
            for i in $(seq 1 "${{ github.event.inputs.domains_count }}"); do echo "test${i}.example.com"; done > "domains/domains.txt"
          fi
          COMBINED_WORDLIST="${{ env.COMBINED_WORDLIST }}"
          if [ ! -s "$COMBINED_WORDLIST" ]; then echo "::error:: Combined wordlist is empty."; exit 0; fi
          rm -f wordlists/chunk-*.txt || true
          split -l "${{ github.event.inputs.words_per_chunk }}" -d -a 5 --additional-suffix=.txt "$COMBINED_WORDLIST" wordlists/chunk-
          if [ -z "$(ls -A wordlists)" ]; then echo "::error:: Split failed to create chunks."; exit 0; fi
          CHUNK_COUNT=$(ls -1 wordlists/chunk-*.txt | wc -l)
          echo "total-chunks=${CHUNK_COUNT}" >> $GITHUB_OUTPUT
          MATRIX_SIZE=${{ env.MATRIX_SIZE }}
          CALCULATED_RUNS=$(( (CHUNK_COUNT + MATRIX_SIZE - 1) / MATRIX_SIZE ))
          USER_MAX_RUNS=${{ github.event.inputs.max_runs }}
          EFFECTIVE_MAX_RUNS=$(( CALCULATED_RUNS < USER_MAX_RUNS ? CALCULATED_RUNS : USER_MAX_RUNS ))
          echo "effective-max-runs=${EFFECTIVE_MAX_RUNS}" >> $GITHUB_OUTPUT
      - name: Upload binaries and wordlists as artifact
        uses: actions/upload-artifact@v4
        with:
          name: wordlists-artifact
          path: |
            wordlists
            resolvers.txt
            resolvers-trusted.txt
            domains/domains.txt


  generate_matrix:
    name: Generate Dynamic Matrix
    runs-on: ubuntu-latest
    needs: prepare
    outputs:
      shard_matrix: ${{ steps.gen_matrix.outputs.shard_matrix }}
    steps:
      - name: Calculate shards for this run
        id: gen_matrix
        run: |
          TOTAL_CHUNKS=${{ needs.prepare.outputs.total-chunks }}
          CHUNK_START=${{ github.event.inputs.chunk_start }}
          MATRIX_SIZE=${{ env.MATRIX_SIZE }}
          CHUNKS_REMAINING=$(( TOTAL_CHUNKS - CHUNK_START ))
          if (( CHUNKS_REMAINING < 0 )); then CHUNKS_REMAINING=0; fi
          SHARDS_THIS_RUN=$(( CHUNKS_REMAINING < MATRIX_SIZE ? CHUNKS_REMAINING : MATRIX_SIZE ))
          if (( SHARDS_THIS_RUN <= 0 )); then
            echo "shard_matrix=[]" >> $GITHUB_OUTPUT
          else
            MATRIX_JSON=$(jq -cn --argjson n "$SHARDS_THIS_RUN" '[range($n)]')
            echo "Generated matrix for ${SHARDS_THIS_RUN} shards: $MATRIX_JSON"
            echo "shard_matrix=$MATRIX_JSON" >> $GITHUB_OUTPUT
          fi

  brute:
    name: bruteforce-shard (shard ${{ matrix.shard }})
    runs-on: ubuntu-latest
    needs: [prepare, generate_matrix]
    if: needs.generate_matrix.outputs.shard_matrix != '[]'
    container:
      image: ghcr.io/pcoder7/spider-puredns-actions:latest
      credentials:
        username: ${{ secrets.GHCR_USER }}
        password: ${{ secrets.GHCR_TOKEN }}    
    strategy:
      fail-fast: false
      matrix:
        shard: ${{ fromJson(needs.generate_matrix.outputs.shard_matrix) }}
    steps:
      - name: Checkout repo (for committing results)
        uses: actions/checkout@v4
        with:
          persist-credentials: false
      - name: Download artifacts (binaries and wordlists)
        uses: actions/download-artifact@v4
        with:
          name: ${{ needs.prepare.outputs.artifact-name }}
          path: .

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.23'

      - name: Cache Go modules & binaries
        uses: actions/cache@v3
        with:
          path: |
            $HOME/go/pkg/mod
            ~/.cache/go-build
            $HOME/go/bin
          key: ${{ runner.os }}-go-cache-${{ github.ref_name }}
          restore-keys: |
            ${{ runner.os }}-go-cache-
          
      - name: Run puredns bruteforce
        shell: bash
        run: |
          CHUNK_INDEX=$(( ${{ github.event.inputs.chunk_start }} + ${{ matrix.shard }} ))
          CHUNK_FILE="wordlists/chunk-$(printf '%05d' "$CHUNK_INDEX").txt"
          if [ ! -f "$CHUNK_FILE" ]; then exit 0; fi
          while IFS= read -r domain || [ -n "$domain" ]; do
            case "$domain" in \#*|"") continue ;; esac
            ROOT_DOMAIN_DIR="results/$domain"
            mkdir -p "$ROOT_DOMAIN_DIR"
            cat "$CHUNK_FILE" | puredns bruteforce "$domain" -r "resolvers.txt" --rate-limit 5000 --rate-limit-trusted 2000 \
              --resolvers-trusted "resolvers-trusted.txt" --wildcard-tests 300 --wildcard-batch 100000 \
              --write "${ROOT_DOMAIN_DIR}/puredns-output-${CHUNK_INDEX}.txt" \
              --write-wildcards "${ROOT_DOMAIN_DIR}/wildcards-${CHUNK_INDEX}.txt" \
              --write-massdns "${ROOT_DOMAIN_DIR}/massdns-${CHUNK_INDEX}.txt" --quiet
          done < "domains/domains.txt"
          
      - name: Perform Port Scanning
        shell: bash
        run: |
          PORTS="80,443,8080,8443,8000" # Using a smaller list for example
          CHUNK_INDEX=$(( ${{ github.event.inputs.chunk_start }} + ${{ matrix.shard }} ))
          while IFS= read -r domain || [ -n "$domain" ]; do
            case "$domain" in \#*|"") continue ;; esac
            ROOT_DOMAIN_DIR="results/$domain"
            MASSDNS_INPUT_FILE="${ROOT_DOMAIN_DIR}/massdns-${CHUNK_INDEX}.txt"
            if [ ! -s "$MASSDNS_INPUT_FILE" ]; then continue; fi
            
            TMP_IP2SUB=$(mktemp)
            TMP_IP_ONLY=$(mktemp)
            TMP_NONCDN=$(mktemp)
            
            awk '$2=="A" { sub(/\.$/,"",$1); print $3, $1 }' "$MASSDNS_INPUT_FILE" | sort -k1,1 > "$TMP_IP2SUB"
            cut -d' ' -f1 "$TMP_IP2SUB" | sort -u > "$TMP_IP_ONLY"
            if [ ! -s "$TMP_IP_ONLY" ]; then rm -f "$TMP_IP2SUB" "$TMP_IP_ONLY"; continue; fi
            
            echo "▶ Filtering non‑CDN IPs with cut-cdn…"
            cat "$TMP_IP_ONLY" | cut-cdn -ua -t 50 -silent -o "$TMP_NONCDN"
            
            if [ -s "$TMP_NONCDN" ]; then
              TMP_NAABU=$(mktemp)
              TMP_RUSTSCAN=$(mktemp)
              
              echo "==================================================================="
              echo "▶ Running smap and rustscan on non‑CDN IPs…"
          
              naabu -l "$TMP_NONCDN" -passive -o "$TMP_NAABU" -no-color -silent || true
              
              # The rustscan command itself remains unchanged as requested              
              rustscan -a "$TMP_NONCDN" -p "$PORTS" --no-banner -T 5000 -b 300 -tries 1 -u 50000 --scan-order "Random" --greppable --accessible > "$TMP_RUSTSCAN" || true
              
              cat "$TMP_RUSTSCAN" | awk -F ' -> ' '{ gsub(/[\[\]]/, "", $2); n = split($2, p, ","); for(i=1;i<=n;i++) print $1 ":" p[i] }' | anew -q "$TMP_NAABU" || true
              
              awk -F: 'NF==2{print $1, $2} NF==1{print $1, ""}' "$TMP_NAABU" | sort -k1,1 | join -t' ' -1 1 -2 1 - "$TMP_IP2SUB" \
                | awk '{ if ($2 ~ /^[0-9]+$/) print $3":"$2; else print $3 }' > "${ROOT_DOMAIN_DIR}/subdomain_ports-${CHUNK_INDEX}.txt"
              
              rm -f "$TMP_NAABU" "$TMP_RUSTSCAN"
            fi
            rm -f "$TMP_IP2SUB" "$TMP_IP_ONLY" "$TMP_NONCDN"
          done < "domains/domains.txt"

      - name: Commit results with race condition handling
        shell: bash
        env:
          PAT_TOKEN: ${{ secrets.PAT_TOKEN }}
          GIT_REPO: ${{ github.repository }}
          GIT_BRANCH: ${{ github.ref_name }}
        run: |
          RESULTS_DIR="${GITHUB_WORKSPACE}/results"
          if [ ! -d "$RESULTS_DIR" ] || [ -z "$(ls -A "$RESULTS_DIR")" ]; then
            echo "Results directory is empty. Nothing to commit."
            exit 0
          fi
          
          TMP_DIR=$(mktemp -d)
          echo "Cloning ${GIT_REPO} to a temporary directory..."
          git clone "https://x-access-token:${PAT_TOKEN}@github.com/${GIT_REPO}.git" "$TMP_DIR"
          cd "$TMP_DIR"
          git checkout "$GIT_BRANCH"
          git config user.name "GitHub Actions Bot"
          git config user.email "actions-bot@users.noreply.github.com"


          merge_and_deduplicate() {
            local source_glob_pattern="$1"
            local destination_file="$2"
            
            # Use find with xargs for POSIX compliance
            found_files=$(find "$RESULTS_DIR" -type f -name "$source_glob_pattern")
            if [ -z "$found_files" ]; then return; fi
            
            echo "Merging files matching '$source_glob_pattern' into '$destination_file'..."
            temp_merged=$(mktemp)
            {
              echo "$found_files" | xargs cat
              if [ -f "$destination_file" ]; then cat "$destination_file"; fi
            } | sort -u > "$temp_merged"
            mv "$temp_merged" "$destination_file"
          }

          run_merge_logic() {
            echo "Applying merge logic..."
            for domain_dir in "${RESULTS_DIR}"/*; do
              if [ ! -d "$domain_dir" ]; then continue; fi
              domain_name=$(basename "$domain_dir")
              dest_repo_dir="results/$domain_name"
              mkdir -p "$dest_repo_dir"
              
              merge_and_deduplicate "$domain_dir/puredns-output-*.txt" "$dest_repo_dir/all_subdomains.txt"
              merge_and_deduplicate "$domain_dir/subdomain_ports-*.txt" "$dest_repo_dir/subdomains_with_ports.txt"
              merge_and_deduplicate "$domain_dir/wildcards-*.txt" "$dest_repo_dir/wildcards.txt"
              merge_and_deduplicate "$domain_dir/massdns-*.txt" "$dest_repo_dir/massdns_records.txt"
            done
            git add results/
          }

          run_merge_logic
          if git diff --cached --quiet; then
            echo "No new unique data to commit from this shard."
            exit 0
          fi
          
          git commit -m "feat: Add puredns results from shard ${{ matrix.shard }} (run ${{ github.run_id }})"
          
          MAX_ATTEMPTS=5
          for (( i=1; i<=MAX_ATTEMPTS; i++ )); do
            echo "[Attempt $i/$MAX_ATTEMPTS] Pushing changes..."
            if git push -v origin "$GIT_BRANCH"; then
              echo "✅ Successfully pushed results on attempt $i."
              exit 0
            fi
            
            echo "Push failed. Fetching, resetting, and re-applying changes."
            git fetch origin "$GIT_BRANCH"
            git reset --hard "origin/${GIT_BRANCH}"
            
            run_merge_logic
            
            if git diff --cached --quiet; then
              echo "No net new changes to commit after syncing with remote."
              exit 0
            fi
            
            git commit -m "feat: Add puredns results from shard ${{ matrix.shard }} (run ${{ github.run_id }}, retry $i)"
            sleep $(( 2 * i ))
          done

          echo "::error:: All push attempts failed after $MAX_ATTEMPTS retries."

          exit 0
  
  dispatch-next:
    name: dispatch-next-run
    runs-on: ubuntu-latest
    
    needs: [prepare, brute]
    if: always()
    env:
      PAT_TOKEN: ${{ secrets.PAT_TOKEN }}
    steps:
      - name: Compute and dispatch next run
        shell: bash
        run: |
          if [ -z "${PAT_TOKEN}" ]; then echo "Error: secrets.PAT_TOKEN is required." >&2; exit 0; fi
          CHUNK_START=${{ github.event.inputs.chunk_start }}
          TOTAL_CHUNKS=${{ needs.prepare.outputs.total-chunks }}
          RUN_COUNTER=${{ github.event.inputs.run_counter }}
          MAX_RUNS=${{ needs.prepare.outputs.effective-max-runs }}
          MATRIX_SIZE=${{ env.MATRIX_SIZE }}
          NEXT_START=$((CHUNK_START + MATRIX_SIZE))
          NEXT_COUNTER=$((RUN_COUNTER + 1))
          echo "Current start: ${CHUNK_START}, Next start: ${NEXT_START}, Total chunks: ${TOTAL_CHUNKS}"
          if [ "$NEXT_START" -ge "$TOTAL_CHUNKS" ]; then echo "All chunks processed. Terminating."; exit 0; fi
          if [ "${NEXT_COUNTER}" -ge "${MAX_RUNS}" ]; then echo "Next run would exceed max_runs limit. Terminating."; exit 0; fi
          URL="https://api.github.com/repos/${{ github.repository }}/actions/workflows/${{ env.WORKFLOW_FILE }}/dispatches"
          BODY=$(printf '{"ref":"%s","inputs":{"chunk_start":"%s","total_chunks":"%s","run_counter":"%s","max_runs":"%s","words_per_chunk":"%s","domains_count":"%s"}}' \
            "${{ github.ref_name }}" "${NEXT_START}" "${TOTAL_CHUNKS}" "${NEXT_COUNTER}" "${MAX_RUNS}" \
            "${{ github.event.inputs.words_per_chunk }}" "${{ github.event.inputs.domains_count }}")
          echo "Dispatching next run..."
          for i in 1 2 3 4; do
            HTTP_STATUS=$(curl -s -o /dev/null -w "%{http_code}" -X POST -H "Accept: application/vnd.github+json" \
              -H "Authorization: Bearer ${PAT_TOKEN}" -H "X-GitHub-Api-Version: 2022-11-28" -d "$BODY" "$URL")
            if [ "$HTTP_STATUS" -ge 200 ] && [ "$HTTP_STATUS" -lt 300 ]; then echo "Dispatch succeeded (HTTP ${HTTP_STATUS})"; exit 0; fi
            echo "Dispatch attempt ${i} failed (HTTP ${HTTP_STATUS}). Retrying..."
            sleep $((i * 2))
          done
          echo "Failed to dispatch next run after retries. Terminating with an error."
          exit 0
